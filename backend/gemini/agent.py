"""
Gemini 3 Agentic Analysis System for Sinkhole Detection

This module implements an autonomous multi-step analysis pipeline using Gemini 3 Pro.
It coordinates satellite imagery analysis, risk assessment, and report generation.

Key Features:
- Multi-step reasoning with thinking_level control
- Thought signatures for maintaining context across analysis steps
- Autonomous monitoring and change detection
- Structured report generation
"""

import asyncio
import json
import base64
import io
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Tuple
from pathlib import Path
from dataclasses import dataclass, field

import numpy as np
from PIL import Image

from backend.config import settings, GeminiConfig, WinterParkAOI


@dataclass
class AnalysisStep:
    """Represents a single step in the agentic analysis pipeline"""
    step_name: str
    status: str = "pending"  # pending, running, completed, failed
    input_data: Dict[str, Any] = field(default_factory=dict)
    output_data: Dict[str, Any] = field(default_factory=dict)
    thought_summary: str = ""
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error: Optional[str] = None


@dataclass 
class AnalysisReport:
    """Final analysis report generated by the agent"""
    report_id: str
    timestamp: datetime
    aoi_name: str
    bbox: Tuple[float, float, float, float]
    
    # Analysis results
    overall_risk_level: str  # low, medium, high, very_high
    confidence: float
    
    # Detected features
    detected_sinkholes: List[Dict[str, Any]] = field(default_factory=list)
    risk_factors: Dict[str, Any] = field(default_factory=dict)
    
    # Data sources used
    data_sources: Dict[str, Any] = field(default_factory=dict)
    
    # Gemini reasoning
    analysis_reasoning: str = ""
    recommendations: List[str] = field(default_factory=list)
    
    # Pipeline metadata
    steps_completed: List[str] = field(default_factory=list)
    total_analysis_time_seconds: float = 0.0


class GeminiAgentClient:
    """
    Gemini 3 Pro client with agentic capabilities
    
    Supports both:
    - Google AI Studio (API key) - for testing/development
    - Vertex AI (service account) - for enterprise/production
    
    Uses Gemini 3's thinking_level parameter for controlled reasoning depth
    and thought signatures for maintaining analysis context.
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or settings.gemini_api_key
        self._model = None
        self._model_name = GeminiConfig.MODEL_NAME
        self._genai_client = None
        self._thought_context = []  # Maintain thought signatures across calls
        self._use_vertex = settings.use_vertex_ai
        self._is_vertex = False
        self._init_client()
    
    def _init_client(self):
        """Initialize Gemini 3 client - supports both AI Studio and Vertex AI"""
        
        print(f"[Gemini] use_vertex_ai = {self._use_vertex}")
        
        if self._use_vertex:
            self._init_vertex_ai()
        else:
            self._init_ai_studio()
    
    def _init_vertex_ai(self):
        """Initialize using Vertex AI with Google Gen AI SDK (supports Gemini 3)"""
        project_id = settings.google_cloud_project
        
        if not project_id:
            raise ValueError(
                "GOOGLE_CLOUD_PROJECT is required for Vertex AI. "
                "Set it in your .env file."
            )
        
        try:
            # Use the new Google Gen AI SDK for Gemini 3 support
            from google import genai
            
            # Gemini 3 Pro Preview requires "global" location
            # This is independent of your org's default region
            gemini_location = "global"
            
            # Initialize client with Vertex AI
            self._genai_client = genai.Client(
                vertexai=True,
                project=project_id,
                location=gemini_location
            )
            
            # Store model name
            self._model_name = GeminiConfig.MODEL_NAME
            self._model = True  # Flag that we're initialized
            self._is_vertex = True
            
            print(f"✓ Gemini 3 Agent initialized via Google Gen AI SDK")
            print(f"  Model: {self._model_name}")
            print(f"  Project: {project_id}, Location: {gemini_location}")
            
        except Exception as e:
            raise RuntimeError(f"Failed to initialize Vertex AI Gemini: {e}")
    
    def _init_ai_studio(self):
        """Initialize using Google AI Studio (API key)"""
        if not self.api_key:
            raise ValueError(
                "Gemini API key is required. Either:\n"
                "1. Set GEMINI_API_KEY for Google AI Studio, or\n"
                "2. Set USE_VERTEX_AI=true with GOOGLE_CLOUD_PROJECT for Vertex AI"
            )
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            
            # Initialize Gemini model
            self._model = genai.GenerativeModel(
                model_name=GeminiConfig.MODEL_NAME,
                generation_config={
                    "temperature": GeminiConfig.TEMPERATURE,
                    "max_output_tokens": GeminiConfig.MAX_OUTPUT_TOKENS,
                }
            )
            self._is_vertex = False
            print(f"✓ Gemini 3 Agent initialized via AI Studio ({GeminiConfig.MODEL_NAME})")
            
        except Exception as e:
            raise RuntimeError(f"Failed to initialize Gemini 3: {e}")
    
    @property
    def is_available(self) -> bool:
        """Check if Gemini is available"""
        return self._model is not None
    
    def _image_to_base64(self, image: np.ndarray) -> str:
        """Convert numpy array to base64 encoded PNG"""
        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image = (image * 255).astype(np.uint8)
            else:
                image = image.astype(np.uint8)
        
        if len(image.shape) == 2:
            image = np.stack([image] * 3, axis=-1)
        
        pil_image = Image.fromarray(image)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='PNG')
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    async def analyze_with_thinking(
        self,
        prompt: str,
        image: Optional[np.ndarray] = None,
        thinking_level: str = "medium",
        include_thoughts: bool = True,
        context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analyze with Gemini 3's thinking capabilities
        
        Args:
            prompt: The analysis prompt
            image: Optional image array to analyze
            thinking_level: "low" for fast, "high" for deep reasoning
            include_thoughts: Whether to include thought summaries
            context: Previous thought context for multi-step analysis
        
        Returns:
            Dictionary with response, thoughts, and metadata
        """
        # Build the full prompt with context
        full_prompt = prompt
        if context:
            full_prompt = f"Previous analysis context:\n{context}\n\n{prompt}"
        
        try:
            if self._use_vertex:
                return await self._analyze_vertex(full_prompt, image, thinking_level)
            else:
                return await self._analyze_ai_studio(full_prompt, image, thinking_level)
            
        except Exception as e:
            return {
                "error": str(e),
                "response": None,
                "thinking_level": thinking_level,
                "timestamp": datetime.utcnow().isoformat(),
            }
    
    async def _analyze_vertex(
        self,
        prompt: str,
        image: Optional[np.ndarray],
        thinking_level: str
    ) -> Dict[str, Any]:
        """Analyze using Google Gen AI SDK with Vertex AI"""
        from google.genai import types
        
        # Prepare content parts
        content_parts = []
        
        if image is not None and image.size > 0:
            # Convert numpy array to bytes
            pil_image = Image.fromarray(image.astype(np.uint8))
            buffer = io.BytesIO()
            pil_image.save(buffer, format='PNG')
            image_bytes = buffer.getvalue()
            
            # Add image as Part
            content_parts.append(
                types.Part.from_bytes(data=image_bytes, mime_type="image/png")
            )
        
        # Add text prompt
        content_parts.append(prompt)
        
        # Generate response using the Gen AI SDK
        response = await asyncio.to_thread(
            self._genai_client.models.generate_content,
            model=self._model_name,
            contents=content_parts,
            config=types.GenerateContentConfig(
                temperature=GeminiConfig.TEMPERATURE,
                max_output_tokens=GeminiConfig.MAX_OUTPUT_TOKENS,
            )
        )
        
        result = {
            "response": response.text,
            "thinking_level": thinking_level,
            "timestamp": datetime.utcnow().isoformat(),
        }
        
        return result
    
    async def _analyze_ai_studio(
        self,
        prompt: str,
        image: Optional[np.ndarray],
        thinking_level: str
    ) -> Dict[str, Any]:
        """Analyze using Google AI Studio"""
        import google.generativeai as genai
        
        # Prepare content parts
        content_parts = []
        if image is not None and image.size > 0:
            image_b64 = self._image_to_base64(image)
            content_parts.append({"mime_type": "image/png", "data": image_b64})
        content_parts.append(prompt)
        
        # Configure generation
        generation_config = genai.GenerationConfig(
            temperature=GeminiConfig.TEMPERATURE,
            max_output_tokens=GeminiConfig.MAX_OUTPUT_TOKENS,
        )
        
        # Generate response
        response = await asyncio.to_thread(
            self._model.generate_content,
            content_parts,
            generation_config=generation_config
        )
        
        result = {
            "response": response.text,
            "thinking_level": thinking_level,
            "timestamp": datetime.utcnow().isoformat(),
        }
        
        # Extract thoughts if available
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                for part in candidate.content.parts:
                    if hasattr(part, 'thought') and part.thought:
                        result["thought_summary"] = part.text
                        self._thought_context.append(part.text)
        
        return result
    
    def get_thought_context(self) -> str:
        """Get accumulated thought context for multi-step analysis"""
        if not self._thought_context:
            return ""
        return "\n\n".join(self._thought_context[-5:])  # Keep last 5 thoughts
    
    def clear_thought_context(self):
        """Clear thought context for new analysis session"""
        self._thought_context = []


class SinkholeAnalysisAgent:
    """
    Autonomous agent for sinkhole susceptibility analysis
    
    Coordinates multi-step analysis pipeline:
    1. Fetch satellite imagery
    2. Analyze imagery with Gemini 3
    3. Integrate with geological data
    4. Generate risk assessment
    5. Produce structured report
    """
    
    def __init__(self):
        self.gemini = GeminiAgentClient()
        self.steps: List[AnalysisStep] = []
        self.current_report: Optional[AnalysisReport] = None
    
    async def run_full_analysis(
        self,
        bbox: Tuple[float, float, float, float],
        include_satellite: bool = True,
        thinking_level: str = "high"
    ) -> AnalysisReport:
        """
        Run complete autonomous analysis pipeline
        
        Args:
            bbox: Bounding box (west, south, east, north)
            include_satellite: Whether to fetch and analyze satellite imagery
            thinking_level: Gemini thinking depth ("low", "medium", "high")
        
        Returns:
            Complete AnalysisReport
        """
        start_time = datetime.utcnow()
        report_id = f"analysis_{start_time.strftime('%Y%m%d_%H%M%S')}"
        
        self.gemini.clear_thought_context()
        self.steps = []
        
        print(f"\n{'='*60}")
        print(f"GEMINI 3 AGENTIC ANALYSIS - {report_id}")
        print(f"{'='*60}")
        print(f"AOI: {bbox}")
        print(f"Thinking Level: {thinking_level}")
        print(f"{'='*60}\n")
        
        # Initialize report
        self.current_report = AnalysisReport(
            report_id=report_id,
            timestamp=start_time,
            aoi_name=WinterParkAOI.NAME,
            bbox=bbox,
            overall_risk_level="unknown",
            confidence=0.0
        )
        
        try:
            # Step 1: Fetch geological data
            await self._step_fetch_geological_data(bbox)
            
            # Step 2: Fetch satellite imagery
            satellite_image = None
            if include_satellite:
                satellite_image = await self._step_fetch_satellite_imagery(bbox)
            
            # Step 3: Analyze imagery with Gemini
            if satellite_image is not None:
                await self._step_analyze_imagery(satellite_image, bbox, thinking_level)
            
            # Step 4: Integrate and assess risk
            await self._step_risk_assessment(bbox, thinking_level)
            
            # Step 5: Generate recommendations
            await self._step_generate_recommendations(thinking_level)
            
            # Finalize report
            end_time = datetime.utcnow()
            self.current_report.total_analysis_time_seconds = (end_time - start_time).total_seconds()
            self.current_report.steps_completed = [s.step_name for s in self.steps if s.status == "completed"]
            
            print(f"\n{'='*60}")
            print(f"ANALYSIS COMPLETE")
            print(f"Total time: {self.current_report.total_analysis_time_seconds:.1f}s")
            print(f"Risk Level: {self.current_report.overall_risk_level}")
            print(f"{'='*60}\n")
            
            return self.current_report
            
        except Exception as e:
            print(f"[!] Analysis failed: {e}")
            self.current_report.overall_risk_level = "error"
            self.current_report.analysis_reasoning = f"Analysis failed: {str(e)}"
            return self.current_report
    
    async def _step_fetch_geological_data(self, bbox: Tuple[float, float, float, float]):
        """Step 1: Fetch geological data from APIs"""
        step = AnalysisStep(step_name="fetch_geological_data")
        step.status = "running"
        step.started_at = datetime.utcnow()
        self.steps.append(step)
        
        print("[Step 1] Fetching geological data...")
        
        try:
            from backend.data.services import RealDataManager
            
            cache_dir = settings.cache_dir if settings.cache_dir else Path("data/cache")
            manager = RealDataManager(cache_dir)
            
            try:
                data = await manager.fetch_all_layers(bbox, include_satellite=False)
                
                step.output_data = {
                    "sinkholes_count": len(data.get("sinkholes", {}).get("features", [])),
                    "geology_count": len(data.get("geology", {}).get("features", [])),
                    "water_count": len(data.get("water", {}).get("features", [])),
                    "karst_units_count": len(data.get("karst_units", [])),
                    "dem_shape": data.get("dem").shape if data.get("dem") is not None else None,
                }
                
                # Store in report
                self.current_report.data_sources = {
                    "sinkholes": {
                        "source": "Florida Geological Survey",
                        "count": step.output_data["sinkholes_count"]
                    },
                    "geology": {
                        "source": "Florida Geological Survey",
                        "count": step.output_data["geology_count"]
                    },
                    "water": {
                        "source": "National Hydrography Dataset",
                        "count": step.output_data["water_count"]
                    },
                    "dem": {
                        "source": "USGS 3DEP",
                        "shape": step.output_data["dem_shape"]
                    }
                }
                
                # Store sinkholes for report
                if data.get("sinkholes"):
                    for feature in data["sinkholes"].get("features", []):
                        geom = feature.get("geometry", {})
                        if geom.get("type") == "Point":
                            coords = geom.get("coordinates", [])
                            props = feature.get("properties", {})
                            self.current_report.detected_sinkholes.append({
                                "source": "FGS Historical",
                                "coordinates": coords,
                                "type": props.get("SINKHOLE_T", "Unknown"),
                                "date": props.get("REPORTED_D", "Unknown"),
                                "confidence": 1.0  # Historical data = confirmed
                            })
                
                step.status = "completed"
                print(f"  ✓ Fetched {step.output_data['sinkholes_count']} sinkholes, "
                      f"{step.output_data['karst_units_count']} karst units")
                
            finally:
                await manager.close()
                
        except Exception as e:
            step.status = "failed"
            step.error = str(e)
            print(f"  ✗ Failed: {e}")
        
        step.completed_at = datetime.utcnow()
    
    async def _step_fetch_satellite_imagery(
        self, 
        bbox: Tuple[float, float, float, float]
    ) -> Optional[np.ndarray]:
        """Step 2: Fetch satellite imagery from Planetary Computer"""
        step = AnalysisStep(step_name="fetch_satellite_imagery")
        step.status = "running"
        step.started_at = datetime.utcnow()
        self.steps.append(step)
        
        print("[Step 2] Fetching satellite imagery...")
        
        try:
            from backend.data.services import SentinelDataService
            
            sentinel = SentinelDataService()
            
            try:
                # Search for recent low-cloud imagery
                end_date = datetime.now().strftime("%Y-%m-%d")
                start_date = (datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d")
                
                scenes = await sentinel.search_sentinel2(
                    bbox=bbox,
                    start_date=start_date,
                    end_date=end_date,
                    max_cloud_cover=20.0,
                    limit=5
                )
                
                if not scenes:
                    print("  ⚠ No suitable Sentinel-2 scenes found")
                    step.status = "completed"
                    step.output_data = {"scenes_found": 0, "image": None}
                    step.completed_at = datetime.utcnow()
                    return None
                
                # Fetch the best scene (lowest cloud cover)
                best_scene = scenes[0]
                scene_date = best_scene.get("properties", {}).get("datetime", "Unknown")
                cloud_cover = best_scene.get("properties", {}).get("eo:cloud_cover", "Unknown")
                
                print(f"  Found {len(scenes)} scenes, using: {scene_date} ({cloud_cover}% clouds)")
                
                # Fetch RGB bands
                band_data = await sentinel.get_sentinel2_tile(
                    item=best_scene,
                    bands=["B04", "B03", "B02"],  # RGB
                    bbox=bbox
                )
                
                if band_data and all(b in band_data for b in ["B04", "B03", "B02"]):
                    # Create RGB composite
                    r = band_data["B04"].astype(np.float32)
                    g = band_data["B03"].astype(np.float32)
                    b = band_data["B02"].astype(np.float32)
                    
                    # Normalize to 0-255
                    def normalize(arr):
                        arr = np.clip(arr, 0, 3000)  # Typical Sentinel-2 range
                        return ((arr / 3000) * 255).astype(np.uint8)
                    
                    rgb = np.stack([normalize(r), normalize(g), normalize(b)], axis=-1)
                    
                    step.output_data = {
                        "scenes_found": len(scenes),
                        "scene_date": scene_date,
                        "cloud_cover": cloud_cover,
                        "image_shape": rgb.shape
                    }
                    
                    self.current_report.data_sources["satellite"] = {
                        "source": "Sentinel-2 L2A (Planetary Computer)",
                        "date": scene_date,
                        "cloud_cover": f"{cloud_cover}%",
                        "bands": ["B04", "B03", "B02"]
                    }
                    
                    step.status = "completed"
                    print(f"  ✓ Fetched image: {rgb.shape}")
                    step.completed_at = datetime.utcnow()
                    return rgb
                else:
                    print("  ⚠ Could not fetch band data")
                    step.status = "completed"
                    step.output_data = {"scenes_found": len(scenes), "image": None}
                    step.completed_at = datetime.utcnow()
                    return None
                    
            finally:
                await sentinel.close()
                
        except Exception as e:
            step.status = "failed"
            step.error = str(e)
            print(f"  ✗ Failed: {e}")
            step.completed_at = datetime.utcnow()
            return None
    
    async def _step_analyze_imagery(
        self,
        image: np.ndarray,
        bbox: Tuple[float, float, float, float],
        thinking_level: str
    ):
        """Step 3: Analyze satellite imagery with Gemini 3"""
        step = AnalysisStep(step_name="analyze_imagery_gemini")
        step.status = "running"
        step.started_at = datetime.utcnow()
        self.steps.append(step)
        
        print(f"[Step 3] Analyzing imagery with Gemini 3 (thinking_level={thinking_level})...")
        
        try:
            prompt = f"""You are an expert geologist analyzing Sentinel-2 satellite imagery for sinkhole susceptibility.

LOCATION: Winter Park, Florida - Central Florida Karst Region
COORDINATES: {bbox}
IMAGE: True-color RGB composite from Sentinel-2 L2A

TASK: Analyze this satellite image for features indicating sinkhole activity or susceptibility.

Look for and identify:
1. CIRCULAR DEPRESSIONS - Round or oval low areas (potential cover-collapse sinkholes)
2. VEGETATION ANOMALIES - Circular patterns of stressed or unusually lush vegetation
3. DRAINAGE PATTERNS - Internal drainage, disappearing water, unusual ponding
4. SUBSIDENCE INDICATORS - Gradual settling zones, concentric patterns
5. KARST TOPOGRAPHY - Surface expressions of underground dissolution

For each feature found, provide:
- Location description within the image
- Feature type
- Confidence level (0-100%)
- Risk assessment

Provide your analysis as JSON:
{{
    "features_detected": [
        {{
            "type": "depression|vegetation_anomaly|drainage_issue|subsidence|karst_feature",
            "location_description": "Description of where in image",
            "confidence_percent": 85,
            "risk_level": "low|medium|high",
            "description": "Detailed description"
        }}
    ],
    "overall_assessment": {{
        "sinkhole_risk": "low|medium|high|very_high",
        "confidence_percent": 80,
        "key_observations": ["List of key findings"],
        "reasoning": "Explanation of risk assessment"
    }},
    "data_quality": {{
        "image_quality": "good|moderate|poor",
        "cloud_interference": true/false,
        "suitable_for_analysis": true/false
    }}
}}"""

            result = await self.gemini.analyze_with_thinking(
                prompt=prompt,
                image=image,
                thinking_level=thinking_level,
                include_thoughts=True
            )
            
            if result.get("error"):
                raise Exception(result["error"])
            
            # Parse response
            response_text = result.get("response", "")
            step.output_data["raw_response"] = response_text
            
            if result.get("thought_summary"):
                step.thought_summary = result["thought_summary"]
                self.current_report.analysis_reasoning += f"\n\nImagery Analysis Reasoning:\n{result['thought_summary']}"
            
            # Try to parse JSON from response
            import re
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                try:
                    analysis = json.loads(json_match.group())
                    step.output_data["analysis"] = analysis
                    
                    # Add Gemini-detected features to report
                    for feature in analysis.get("features_detected", []):
                        self.current_report.detected_sinkholes.append({
                            "source": "Gemini 3 Analysis",
                            "type": feature.get("type"),
                            "description": feature.get("description"),
                            "confidence": feature.get("confidence_percent", 0) / 100,
                            "risk_level": feature.get("risk_level")
                        })
                    
                    # Store overall assessment
                    overall = analysis.get("overall_assessment", {})
                    self.current_report.risk_factors["gemini_assessment"] = overall
                    
                except json.JSONDecodeError:
                    step.output_data["parse_error"] = "Could not parse JSON from response"
            
            step.status = "completed"
            print(f"  ✓ Gemini analysis complete")
            
        except Exception as e:
            step.status = "failed"
            step.error = str(e)
            print(f"  ✗ Failed: {e}")
        
        step.completed_at = datetime.utcnow()
    
    async def _step_risk_assessment(
        self,
        bbox: Tuple[float, float, float, float],
        thinking_level: str
    ):
        """Step 4: Integrate all data and assess overall risk"""
        step = AnalysisStep(step_name="risk_assessment")
        step.status = "running"
        step.started_at = datetime.utcnow()
        self.steps.append(step)
        
        print(f"[Step 4] Performing integrated risk assessment...")
        
        try:
            # Gather all collected data
            historical_sinkholes = len([s for s in self.current_report.detected_sinkholes 
                                        if s.get("source") == "FGS Historical"])
            gemini_detections = len([s for s in self.current_report.detected_sinkholes 
                                     if s.get("source") == "Gemini 3 Analysis"])
            
            context = self.gemini.get_thought_context()
            
            prompt = f"""You are synthesizing a final sinkhole susceptibility assessment.

LOCATION: Winter Park, Florida
COORDINATES: {bbox}

DATA COLLECTED:
- Historical sinkholes from Florida Geological Survey: {historical_sinkholes}
- Features detected by satellite imagery analysis: {gemini_detections}
- Geological context: Central Florida Karst (Floridan Aquifer System)
- Data sources: {json.dumps(self.current_report.data_sources, indent=2)}

PREVIOUS ANALYSIS:
{context}

DETECTED FEATURES:
{json.dumps(self.current_report.detected_sinkholes[:10], indent=2)}

TASK: Provide a final integrated risk assessment considering all data sources.

Consider:
1. Proximity to historical sinkholes
2. Karst geology presence (limestone, dolomite)
3. Satellite imagery analysis findings
4. Drainage patterns and hydrology
5. Land use and development pressure

Provide your assessment as JSON:
{{
    "overall_risk_level": "low|medium|high|very_high",
    "confidence_percent": 85,
    "risk_factors": {{
        "historical_sinkhole_proximity": {{
            "level": "low|medium|high",
            "weight": 0.3,
            "reasoning": "Explanation"
        }},
        "karst_geology": {{
            "level": "high",
            "weight": 0.3,
            "reasoning": "Winter Park is underlain by Floridan Aquifer limestone"
        }},
        "satellite_indicators": {{
            "level": "medium",
            "weight": 0.2,
            "reasoning": "Based on imagery analysis"
        }},
        "hydrology": {{
            "level": "medium",
            "weight": 0.2,
            "reasoning": "Based on drainage patterns"
        }}
    }},
    "summary": "2-3 sentence summary of findings",
    "confidence_factors": ["Factors supporting confidence level"]
}}"""

            result = await self.gemini.analyze_with_thinking(
                prompt=prompt,
                thinking_level=thinking_level,
                include_thoughts=True,
                context=context
            )
            
            if result.get("error"):
                raise Exception(result["error"])
            
            response_text = result.get("response", "")
            step.output_data["raw_response"] = response_text
            
            if result.get("thought_summary"):
                step.thought_summary = result["thought_summary"]
                self.current_report.analysis_reasoning += f"\n\nRisk Assessment Reasoning:\n{result['thought_summary']}"
            
            # Parse response
            import re
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                try:
                    assessment = json.loads(json_match.group())
                    step.output_data["assessment"] = assessment
                    
                    # Update report
                    self.current_report.overall_risk_level = assessment.get("overall_risk_level", "unknown")
                    self.current_report.confidence = assessment.get("confidence_percent", 0) / 100
                    self.current_report.risk_factors.update(assessment.get("risk_factors", {}))
                    
                    if assessment.get("summary"):
                        self.current_report.analysis_reasoning += f"\n\nSummary: {assessment['summary']}"
                    
                except json.JSONDecodeError:
                    step.output_data["parse_error"] = "Could not parse JSON"
            
            step.status = "completed"
            print(f"  ✓ Risk assessment: {self.current_report.overall_risk_level} "
                  f"(confidence: {self.current_report.confidence:.0%})")
            
        except Exception as e:
            step.status = "failed"
            step.error = str(e)
            print(f"  ✗ Failed: {e}")
        
        step.completed_at = datetime.utcnow()
    
    async def _step_generate_recommendations(self, thinking_level: str):
        """Step 5: Generate actionable recommendations"""
        step = AnalysisStep(step_name="generate_recommendations")
        step.status = "running"
        step.started_at = datetime.utcnow()
        self.steps.append(step)
        
        print(f"[Step 5] Generating recommendations...")
        
        try:
            context = self.gemini.get_thought_context()
            
            prompt = f"""Based on the sinkhole susceptibility analysis for Winter Park, Florida, generate actionable recommendations.

RISK LEVEL: {self.current_report.overall_risk_level}
CONFIDENCE: {self.current_report.confidence:.0%}
FEATURES DETECTED: {len(self.current_report.detected_sinkholes)}

PREVIOUS ANALYSIS:
{context[:2000]}

Generate 3-5 specific, actionable recommendations for:
1. Property owners in high-risk areas
2. Local government/planning departments
3. Further investigation priorities

Respond as JSON:
{{
    "recommendations": [
        {{
            "priority": "high|medium|low",
            "target_audience": "property_owners|government|researchers",
            "recommendation": "Specific actionable recommendation",
            "reasoning": "Why this is important"
        }}
    ],
    "monitoring_suggestions": [
        "Suggestion for ongoing monitoring"
    ],
    "data_gaps": [
        "Areas where more data would improve assessment"
    ]
}}"""

            result = await self.gemini.analyze_with_thinking(
                prompt=prompt,
                thinking_level="low",  # Recommendations don't need deep thinking
                include_thoughts=False
            )
            
            if result.get("error"):
                raise Exception(result["error"])
            
            response_text = result.get("response", "")
            
            # Parse response
            import re
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                try:
                    recs = json.loads(json_match.group())
                    step.output_data["recommendations"] = recs
                    
                    # Add to report
                    for rec in recs.get("recommendations", []):
                        self.current_report.recommendations.append(
                            f"[{rec.get('priority', 'medium').upper()}] {rec.get('recommendation')}"
                        )
                    
                except json.JSONDecodeError:
                    pass
            
            step.status = "completed"
            print(f"  ✓ Generated {len(self.current_report.recommendations)} recommendations")
            
        except Exception as e:
            step.status = "failed"
            step.error = str(e)
            print(f"  ✗ Failed: {e}")
        
        step.completed_at = datetime.utcnow()
    
    def get_report_dict(self) -> Dict[str, Any]:
        """Convert current report to dictionary for JSON serialization"""
        if not self.current_report:
            return {}
        
        return {
            "report_id": self.current_report.report_id,
            "timestamp": self.current_report.timestamp.isoformat(),
            "aoi": {
                "name": self.current_report.aoi_name,
                "bbox": list(self.current_report.bbox)
            },
            "risk_assessment": {
                "level": self.current_report.overall_risk_level,
                "confidence": self.current_report.confidence
            },
            "detected_features": self.current_report.detected_sinkholes,
            "risk_factors": self.current_report.risk_factors,
            "data_sources": self.current_report.data_sources,
            "analysis_reasoning": self.current_report.analysis_reasoning,
            "recommendations": self.current_report.recommendations,
            "metadata": {
                "steps_completed": self.current_report.steps_completed,
                "total_time_seconds": self.current_report.total_analysis_time_seconds,
                "gemini_model": GeminiConfig.MODEL_NAME
            }
        }


class GeminiMLValidator:
    """
    Gemini-based validation layer for ML predictions
    
    This class provides AI-powered validation and calibration of 
    ML model predictions, adding reasoning and context awareness.
    
    HYBRID APPROACH:
    - ML Model: Fast heatmap tile generation (milliseconds)
    - Gemini: Validates predictions, provides reasoning, adjusts confidence
    """
    
    def __init__(self):
        self.gemini = GeminiAgentClient()
    
    async def validate_tile_prediction(
        self,
        bounds: Tuple[float, float, float, float],
        ml_susceptibility: float,  # Average ML prediction for tile (0-1)
        data_coverage: Dict[str, bool],  # Which data sources were available
        historical_sinkholes_nearby: int,  # Count of FGS sinkholes in/near tile
        satellite_image: Optional[np.ndarray] = None
    ) -> Dict[str, Any]:
        """
        Validate a single tile's ML prediction with Gemini reasoning
        
        Returns:
            {
                "validated_susceptibility": float,  # Potentially adjusted
                "confidence": float,
                "reasoning": str,
                "data_quality_assessment": str,
                "warnings": list
            }
        """
        # Build context about what data was available
        available_sources = [k for k, v in data_coverage.items() if v]
        missing_sources = [k for k, v in data_coverage.items() if not v]
        
        prompt = f"""You are validating an ML model's sinkhole susceptibility prediction.

LOCATION: Winter Park, Florida (Central Florida Karst Region)
TILE BOUNDS: {bounds}

ML MODEL PREDICTION:
- Susceptibility Score: {ml_susceptibility:.2f} (0=low, 1=very high)
- Historical Sinkholes Nearby: {historical_sinkholes_nearby}

DATA AVAILABILITY:
- Available: {', '.join(available_sources) if available_sources else 'None'}
- Missing: {', '.join(missing_sources) if missing_sources else 'None'}

GEOLOGICAL CONTEXT:
- Winter Park is underlain by Floridan Aquifer limestone
- Area is within the Central Florida Karst District
- Cover-collapse and cover-subsidence sinkholes are common

TASK: Validate and potentially adjust the ML prediction.

Consider:
1. Does the ML score align with the number of historical sinkholes?
2. How does missing data affect confidence?
3. Is the karst geology context appropriately reflected?

Respond as JSON:
{{
    "validated_susceptibility": {ml_susceptibility:.2f},
    "adjustment_reason": "No adjustment needed" or "Reason for adjustment",
    "confidence": 0.85,
    "confidence_factors": ["List of factors affecting confidence"],
    "data_quality": "good|moderate|poor",
    "warnings": ["Any warnings about this prediction"]
}}"""

        try:
            result = await self.gemini.analyze_with_thinking(
                prompt=prompt,
                image=satellite_image,
                thinking_level="low",  # Fast validation
                include_thoughts=False
            )
            
            if result.get("error"):
                return {
                    "validated_susceptibility": ml_susceptibility,
                    "confidence": 0.5,
                    "reasoning": f"Validation failed: {result['error']}",
                    "data_quality_assessment": "unknown",
                    "warnings": ["Gemini validation unavailable"]
                }
            
            # Parse response
            response_text = result.get("response", "")
            
            import re
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                validation = json.loads(json_match.group())
                return {
                    "validated_susceptibility": validation.get("validated_susceptibility", ml_susceptibility),
                    "confidence": validation.get("confidence", 0.7),
                    "reasoning": validation.get("adjustment_reason", ""),
                    "data_quality_assessment": validation.get("data_quality", "moderate"),
                    "warnings": validation.get("warnings", [])
                }
            
            return {
                "validated_susceptibility": ml_susceptibility,
                "confidence": 0.7,
                "reasoning": "Could not parse validation response",
                "data_quality_assessment": "moderate",
                "warnings": []
            }
            
        except Exception as e:
            return {
                "validated_susceptibility": ml_susceptibility,
                "confidence": 0.5,
                "reasoning": f"Validation error: {str(e)}",
                "data_quality_assessment": "unknown",
                "warnings": [str(e)]
            }
    
    async def validate_scan_summary(
        self,
        total_tiles: int,
        avg_susceptibility: float,
        high_risk_tiles: int,
        data_coverage_summary: Dict[str, float],  # % of tiles with each data source
        historical_sinkholes_total: int,
        ground_displacement: Optional[Dict[str, Any]] = None  # NASA OPERA InSAR data
    ) -> Dict[str, Any]:
        """
        Validate overall scan results with Gemini reasoning
        
        Called after a Quick Scan or Train+Scan completes to provide
        AI interpretation of the ML results.
        
        Args:
            total_tiles: Number of tiles analyzed
            avg_susceptibility: Mean susceptibility score (0-1)
            high_risk_tiles: Count of tiles with susceptibility > 0.6
            data_coverage_summary: % coverage for each data source
            historical_sinkholes_total: Count of FGS sinkholes in area
            ground_displacement: Optional NASA OPERA InSAR displacement data dict
        """
        # Build ground displacement summary if available
        gd_summary = "NOT AVAILABLE - NASA OPERA InSAR data unavailable for this area"
        if ground_displacement:
            disp = ground_displacement.get("displacement_mm")
            vel = ground_displacement.get("velocity_mm_year")
            coh = ground_displacement.get("coherence")
            
            gd_summary = f"""GROUND DISPLACEMENT DATA (NASA OPERA DISP-S1):
- Data Source: NASA OPERA InSAR (Sentinel-1)
- Maximum Subsidence: {np.nanmin(disp):.1f} mm (negative = subsidence)
- Maximum Uplift: {np.nanmax(disp):.1f} mm
- Mean Displacement: {np.nanmean(disp):.1f} mm"""
            
            if vel is not None:
                subsidence_rate = -np.nanmin(vel)  # Make subsidence positive
                gd_summary += f"""
- Velocity (deformation rate): {np.nanmin(vel):.1f} to {np.nanmax(vel):.1f} mm/year
- Max Subsidence Rate: {subsidence_rate:.1f} mm/year"""
                
                # Add risk interpretation
                if subsidence_rate > 20:
                    gd_summary += "\n- ⚠️ CRITICAL: Subsidence rate exceeds 20mm/year - active collapse risk!"
                elif subsidence_rate > 10:
                    gd_summary += "\n- ⚠️ WARNING: Significant subsidence (>10mm/year) detected"
                elif subsidence_rate > 5:
                    gd_summary += "\n- CAUTION: Moderate subsidence (5-10mm/year) detected"
            
            if coh is not None:
                gd_summary += f"""
- Data Quality (coherence): {np.nanmean(coh):.2f} (0-1, higher=better)"""
        
        prompt = f"""You are providing expert analysis of a sinkhole susceptibility scan with InSAR ground displacement data.

SCAN SUMMARY:
- Location: Winter Park, Florida
- Total Tiles Analyzed: {total_tiles}
- Average Susceptibility: {avg_susceptibility:.2f} (0-1 scale)
- High Risk Tiles (>0.6): {high_risk_tiles} ({100*high_risk_tiles/max(1,total_tiles):.1f}%)
- Historical Sinkholes in Area: {historical_sinkholes_total}

DATA COVERAGE:
{json.dumps(data_coverage_summary, indent=2)}

{gd_summary}

GEOLOGICAL CONTEXT:
- Central Florida Karst - one of the most sinkhole-prone regions in the US
- Underlain by Eocene-Oligocene limestone (Ocala, Suwannee formations)
- Floridan Aquifer System with active groundwater dissolution

CRITICAL SUBSIDENCE THRESHOLDS:
- >20 mm/year: VERY HIGH risk - active collapse process likely
- 10-20 mm/year: HIGH risk - significant subsidence requiring immediate attention
- 5-10 mm/year: MODERATE risk - subsidence occurring, monitoring required
- <5 mm/year: LOW risk - within normal ground movement range

TASK: Provide expert interpretation integrating ML predictions with ground displacement data.

Consider:
1. Does ground displacement data show ACTIVE SUBSIDENCE?
2. Do subsidence locations correlate with ML high-risk areas?
3. What is the combined risk level considering both ML and InSAR data?
4. Should an alert be issued based on displacement rates?

Respond as JSON:
{{
    "overall_assessment": "Summary assessment integrating ML and ground displacement",
    "risk_category": "low|moderate|elevated|high|very_high",
    "confidence_percent": 85,
    "ground_displacement_analysis": {{
        "active_subsidence_detected": true/false,
        "max_subsidence_rate_mm_year": 0.0,
        "risk_level": "critical|high|moderate|low|minimal",
        "correlation_with_ml": "Description of how displacement correlates with ML predictions"
    }},
    "key_findings": ["List of key findings"],
    "data_quality_notes": "Notes about data coverage and reliability",
    "recommendations": [
        {{
            "priority": "high|medium|low",
            "recommendation": "Specific action",
            "reasoning": "Why this matters"
        }}
    ],
    "areas_of_concern": ["Specific concerns"],
    "positive_indicators": ["Any positive findings"],
    "alert_recommended": true/false,
    "alert_level": "NONE|ADVISORY|WATCH|WARNING|EMERGENCY",
    "alert_message": "Message for authorities if alert recommended"
}}"""

        try:
            result = await self.gemini.analyze_with_thinking(
                prompt=prompt,
                thinking_level="medium",
                include_thoughts=True
            )
            
            if result.get("error"):
                return {
                    "overall_assessment": f"ML scan complete. Gemini validation unavailable: {result['error']}",
                    "risk_category": self._ml_score_to_category(avg_susceptibility),
                    "confidence_percent": 50,
                    "key_findings": [f"Analyzed {total_tiles} tiles", f"Found {high_risk_tiles} high-risk areas"],
                    "recommendations": []
                }
            
            response_text = result.get("response", "")
            
            import re
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                return json.loads(json_match.group())
            
            return {
                "overall_assessment": response_text[:500] if response_text else "Analysis complete",
                "risk_category": self._ml_score_to_category(avg_susceptibility),
                "confidence_percent": 70,
                "key_findings": [f"Analyzed {total_tiles} tiles"],
                "recommendations": []
            }
            
        except Exception as e:
            return {
                "overall_assessment": f"ML scan complete. Error in Gemini validation: {str(e)}",
                "risk_category": self._ml_score_to_category(avg_susceptibility),
                "confidence_percent": 50,
                "key_findings": [],
                "recommendations": []
            }
    
    def _ml_score_to_category(self, score: float) -> str:
        """Convert ML susceptibility score to risk category"""
        if score < 0.2:
            return "low"
        elif score < 0.4:
            return "moderate"
        elif score < 0.6:
            return "elevated"
        elif score < 0.8:
            return "high"
        else:
            return "very_high"
